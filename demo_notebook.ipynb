{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of AWSome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rename all the files from a bucket with a foo/bar/ prefix and copy them to another bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from awsome import s3\n",
    "from awsome.development import s3_sandbox, dry_run\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the function that will do the renaming/copy intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervention():\n",
    "    keys = s3.ls('s3://testbucket/foo/bar/')\n",
    "    for key in keys:\n",
    "        new_key = key.replace('customers', 'clients')\n",
    "        # Rename all objects with the same key\n",
    "        s3.move_key(from_bucket='testbucket', from_key=key, to_bucket='testbucket', to_key=new_key)\n",
    "        # Move all objects to the production bucket with the same key\n",
    "        s3.move_key(from_bucket='testbucket', from_key=new_key, to_bucket='prodbucket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the script in production we should do a few tests to make sure it's doing what we think it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create some dummy files that mimic the structure of the files in our real aws instance to test the intervention on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    for i in range(1, 6):\n",
    "        # Files we will be changing\n",
    "        key = f'foo/bar/customers_{i}.csv'\n",
    "        s3.upload_string(data='some data', bucket='testbucket', key=key)\n",
    "        \n",
    "        # Files we want untouched\n",
    "        key = f'foo/baz/companies_{i}.csv'\n",
    "        s3.upload_string(data='some data', bucket='testbucket', key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the test data is created correctly. Of course we don't want to actually create those dummy files in aws. \n",
    "\n",
    "Instead we use the debug_environment context manager that provides a moto s3 instance where we can run our tests as they would run in a real S3 instance. We just need to pass it the name of the buckets it needs to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test bucket:\n",
      "[   'foo/bar/customers_1.csv',\n",
      "    'foo/bar/customers_2.csv',\n",
      "    'foo/bar/customers_3.csv',\n",
      "    'foo/bar/customers_4.csv',\n",
      "    'foo/bar/customers_5.csv',\n",
      "    'foo/baz/companies_1.csv',\n",
      "    'foo/baz/companies_2.csv',\n",
      "    'foo/baz/companies_3.csv',\n",
      "    'foo/baz/companies_4.csv',\n",
      "    'foo/baz/companies_5.csv']\n",
      "\n",
      "Prod bucket:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with s3_sandbox(['testbucket', 'prodbucket']):\n",
    "    create_test_data()\n",
    "    print('Test bucket:')\n",
    "    pp.pprint(s3.ls('s3://testbucket/', recursive=True))\n",
    "    print('\\nProd bucket:')\n",
    "    pp.pprint(s3.ls('s3://prodbucket/', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the sample data has been created correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the intervention script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the script does what we want it to we will execute it with a dry run. This means that we won't actually execute the commands, just print the equivalent aws cli commands so we can visually inspect them.\n",
    "\n",
    "One exception is that we don't want to patch the ls function (it doesn't change S3 so it is reasonable not to patch it) because we depend on its output to generate the rest of the commands. We will need set patch_ls to false.\n",
    "\n",
    "The dry run context manager also creates a moto instance of S3 so we can rest assured that everything will execute in a sandbox and won't affect our real S3 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 mv s3://testbucket/foo/bar/customers_3.csv s3://testbucket/foo/bar/clients_3.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/clients_3.csv s3://prodbucket/foo/bar/clients_3.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/customers_2.csv s3://testbucket/foo/bar/clients_2.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/clients_2.csv s3://prodbucket/foo/bar/clients_2.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/customers_5.csv s3://testbucket/foo/bar/clients_5.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/clients_5.csv s3://prodbucket/foo/bar/clients_5.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/customers_4.csv s3://testbucket/foo/bar/clients_4.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/clients_4.csv s3://prodbucket/foo/bar/clients_4.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/customers_1.csv s3://testbucket/foo/bar/clients_1.csv\n",
      "aws s3 mv s3://testbucket/foo/bar/clients_1.csv s3://prodbucket/foo/bar/clients_1.csv\n"
     ]
    }
   ],
   "source": [
    "with dry_run(['testbucket', 'prodbucket'], patch_ls=False):\n",
    "    create_test_data()\n",
    "    intervention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the intervention script in a sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where it gets interesting. We have inspected the dry run and everything looks reasonable, but you can never be too careful. To make sure we get it right we will execute the real script inside a moto S3 sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test bucket before:\n",
      "[   'foo/bar/customers_1.csv',\n",
      "    'foo/bar/customers_2.csv',\n",
      "    'foo/bar/customers_3.csv',\n",
      "    'foo/bar/customers_4.csv',\n",
      "    'foo/bar/customers_5.csv',\n",
      "    'foo/baz/companies_1.csv',\n",
      "    'foo/baz/companies_2.csv',\n",
      "    'foo/baz/companies_3.csv',\n",
      "    'foo/baz/companies_4.csv',\n",
      "    'foo/baz/companies_5.csv']\n",
      "\n",
      "Prod bucket before:\n",
      "[]\n",
      "\n",
      "\n",
      "Test bucket after:\n",
      "[   'foo/baz/companies_1.csv',\n",
      "    'foo/baz/companies_2.csv',\n",
      "    'foo/baz/companies_3.csv',\n",
      "    'foo/baz/companies_4.csv',\n",
      "    'foo/baz/companies_5.csv']\n",
      "\n",
      "Prod bucket after:\n",
      "[   'foo/bar/clients_1.csv',\n",
      "    'foo/bar/clients_2.csv',\n",
      "    'foo/bar/clients_3.csv',\n",
      "    'foo/bar/clients_4.csv',\n",
      "    'foo/bar/clients_5.csv']\n"
     ]
    }
   ],
   "source": [
    "with s3_sandbox(['testbucket', 'prodbucket']):\n",
    "    create_test_data()\n",
    "    print('Test bucket before:')\n",
    "    pp.pprint(s3.ls('s3://testbucket/', recursive=True))\n",
    "    print('\\nProd bucket before:')\n",
    "    pp.pprint(s3.ls('s3://prodbucket/', recursive=True))\n",
    "    \n",
    "    intervention()\n",
    "    \n",
    "    print('\\n\\nTest bucket after:')\n",
    "    pp.pprint(s3.ls('s3://testbucket/', recursive=True))\n",
    "    print('\\nProd bucket after:')\n",
    "    pp.pprint(s3.ls('s3://prodbucket/', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have succesfully validated our script, and we can rest assured that it will do what we intend it to."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
